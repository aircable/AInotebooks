{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed95806e",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Purpose of the Lecture\n",
    "To introduce fundamental PyTorch concepts by building a model for a common image classification task.\n",
    "\n",
    "## The MNIST Example\n",
    "The MNIST dataset consists of handwritten digits 0-9. In this lecture, we'll build a Convolutional Neural Network (CNN) to classify these digits.\n",
    "\n",
    "## Why this Example?\n",
    "- MNIST is a classic \"hello world\" dataset for image classification, making it ideal for beginners.\n",
    "- CNNs are a fundamental type of neural network for image tasks.\n",
    "- PyTorch is a popular deep learning framework known for its flexibility and ease of use.\n",
    "\n",
    "## Learning Outcomes\n",
    "Students will learn:\n",
    "- How to load and prepare image data in PyTorch.\n",
    "- The concept of Tensors.\n",
    "- How to define a simple CNN architecture.\n",
    "- The roles of an optimizer and a loss function.\n",
    "- The basic training loop: forward pass, loss calculation, backward pass (backpropagation), and optimizer step.\n",
    "- How to evaluate a model's performance.\n",
    "\n",
    "## Brief Explanation of Key Concepts (for absolute beginners)\n",
    "- **Neural Network (NN):** A computing system inspired by the human brain, composed of interconnected processing units (neurons) that learn from data to perform tasks.\n",
    "- **Convolutional Neural Network (CNN):** A specialized type of NN particularly effective for image processing, using layers that apply \"filters\" to detect patterns like edges, shapes, and textures.\n",
    "- **Tensor:** The primary data structure in PyTorch (similar to NumPy arrays but with GPU support). Think of them as multi-dimensional arrays that can hold numbers.\n",
    "- **Training:** The process of teaching a neural network by showing it examples (data) and adjusting its internal parameters (weights) to minimize errors.\n",
    "- **Epoch:** One complete pass through the entire training dataset.\n",
    "- **Batch:** A small subset of the training data processed at one time during an epoch.\n",
    "- **Loss Function:** A way to measure how wrong the model's predictions are compared to the actual labels. The goal of training is to minimize this loss.\n",
    "- **Optimizer:** An algorithm that adjusts the model's parameters based on the loss to improve its performance (e.g., Adam, SGD).\n",
    "- **Activation Function (e.g., ReLU):** A function applied to the output of neurons to introduce non-linearity, allowing the network to learn complex patterns.\n",
    "- **Softmax:** An activation function often used in the final layer of a classification network to convert raw scores (logits) into probabilities for each class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dea1506",
   "metadata": {},
   "source": [
    "# 1. Load Libraries\n",
    "\n",
    "This cell imports all necessary Python libraries used in this notebook.\n",
    "\n",
    "- **torch, torch.nn, torch.nn.functional**: Core PyTorch libraries for building neural networks.\n",
    "- **torchvision, torchvision.transforms, torchvision.datasets**: For accessing standard datasets (like MNIST) and image transformation tools.\n",
    "- **matplotlib.pyplot**: For plotting images.\n",
    "- **numpy**: For numerical operations (though PyTorch tensors are preferred for model building).\n",
    "- **tqdm**: For displaying progress bars during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b8a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a3d470",
   "metadata": {},
   "source": [
    "# 2. Read / Import Data\n",
    "\n",
    "This cell loads the MNIST dataset and prepares it for training and testing.\n",
    "\n",
    "- **BATCH_SIZE**: Data is processed in batches for memory efficiency and stable gradient estimation.\n",
    "- **transforms.Compose and transforms.ToTensor()**: Convert images into PyTorch tensors, the data format the model expects. Normalizing pixel values to a range (usually 0 to 1) is implicitly handled by `ToTensor` for PIL Images.\n",
    "- **torchvision.datasets.MNIST**: PyTorch provides easy access to the MNIST dataset.\n",
    "- **root='./data'**: Directory where the data will be downloaded/stored.\n",
    "- **train=True/False**: Separate datasets for training the model and testing its performance on unseen data.\n",
    "- **download=True**: Automatically downloads the dataset if not found locally.\n",
    "- **transform=transform**: Applies the defined tensor transformation to the images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a071adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 # or 64, 128\n",
    "\n",
    "## transform the data into 'tensors' using the 'transforms' module\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "## download training dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "## download testing dataset\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4ec1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load Data on DataLoader\n",
    "# Feed data in batches into deep-learning models\n",
    "# num_workers=0 in Windows machine\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782f5f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Explore the Data (EDA)\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    #img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "## get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "## show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285418bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dimensions of a batch:\n",
    "for images, labels in trainloader:\n",
    "    print(\"Image batch dimensions:\", images.shape)\n",
    "    print(\"Image label dimensions:\", labels.shape)\n",
    "    break\n",
    "# Image batch dimensions: torch.Size([32, 1, 28, 28]) -->\n",
    "# 32: samples, 1 color channel, 28 x 28 (height x width)\n",
    "# Image label dimensions: torch.Size([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create a model, optimizer and criterion\n",
    "# The model below consists of an __init__() portion where you include the layers and components of the neural network.\n",
    "# In our model, we have a convolutional layer denoted by nn.Conv2d(...).\n",
    "# We are dealing with an image dataset that is in grayscale so we only need one channel going in, so \"in_channels=1\".\n",
    "# We hope to get a nice representation of this layer, so we use \"out_channels=32\".\n",
    "# Kernel size is 3, and for the rest of parameters, we use the default values which you can find here.\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        # 28x28x1 => 26x26x32\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "        self.d1 = nn.Linear(26 * 26 * 32, 128) # 128 represents the size we want as output, and (26*26*32) represents the dimension of the incoming data\n",
    "        self.d2 = nn.Linear(128, 10) #  The same applies for the second dense layer (d2) where the dimension of the output of the previous linear layer was added as in_features=128,\n",
    "        # and 10 is the size of the output (It should be same the final number of classes we want to predict)\n",
    "\n",
    "        # To see how to calculate this, go to https://pytorch.org/docs/stable/nn.html?highlight=linear#conv2d\n",
    "\n",
    "        # Apply an activation function such as ReLU in the middle of each layer\n",
    "        # For prediction purposes, we then apply a softmax layer to the last transformation and return the output of that.\n",
    "    def forward(self, x):\n",
    "    # 32x1x28x28 => 32x32x26x26\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # flatten => 32 x (32*26*26)\n",
    "        x = x.flatten(start_dim = 1)\n",
    "\n",
    "        # 32 x (32*26*26) => 32x128\n",
    "        x = self.d1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # logits => 32x10\n",
    "        logits = self.d2(x)\n",
    "        out = F.softmax(logits, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4999327",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5.1. Test one batch\n",
    "model = MyModel()\n",
    "## We always want to test 1 batch\n",
    "for images, labels in trainloader:\n",
    "    print(\"batch size:\", images.shape)\n",
    "    out = model(images)\n",
    "    print(out.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8883c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5.2 optimizer and criterion\n",
    "# Define Model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MyModel()\n",
    "model = model.to(device)\n",
    "# Learning Rate / Epoch\n",
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# criterion\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5edf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Train the Model\n",
    "## Custom accuracy function\n",
    "def get_accuracy(logit, target, batch_size):\n",
    "    ''' Obtain accuracy for training round '''\n",
    "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100.0 * corrects/batch_size\n",
    "    return accuracy.item()\n",
    "for epoch in range(num_epochs):\n",
    "    train_running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "\n",
    "    model = model.train()\n",
    "\n",
    "    ## training step\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        ## forward + backprop + loss\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        ## update model params\n",
    "        optimizer.step()\n",
    "\n",
    "        train_running_loss += loss.detach().item()\n",
    "        train_acc += get_accuracy(logits, labels, BATCH_SIZE)\n",
    "\n",
    "    model.eval()\n",
    "    print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' \\\n",
    "          %(epoch, train_running_loss / i, train_acc/i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d450693",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Test the Model\n",
    "test_acc = 0.0\n",
    "for i, (images, labels) in enumerate(testloader, 0):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    test_acc += get_accuracy(outputs, labels, BATCH_SIZE)\n",
    "\n",
    "print('Avg. Test Accuracy: %.2f'%( test_acc/i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
